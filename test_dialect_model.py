#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ë°©ì–¸ ê²€ì¶œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ëª¨ë¸ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ëŠ”ì§€, ì–´íœ˜ ì‚¬ì „ì´ ì œëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
"""

import os
import sys

def test_dependencies():
    """ì˜ì¡´ì„± íŒ¨í‚¤ì§€ í™•ì¸"""
    print("\n" + "="*60)
    print("ğŸ“¦ ì˜ì¡´ì„± í™•ì¸")
    print("="*60)
    
    required = {
        'transformers': 'Hugging Face Transformers',
        'torch': 'PyTorch',
        'numpy': 'NumPy',
        'soundfile': 'SoundFile'
    }
    
    missing = []
    
    for package, name in required.items():
        try:
            module = __import__(package)
            version = getattr(module, '__version__', 'unknown')
            print(f"âœ… {name}: {version}")
        except ImportError:
            print(f"âŒ {name}: ë¯¸ì„¤ì¹˜")
            missing.append(package)
    
    if missing:
        print(f"\nâš ï¸  ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {', '.join(missing)}")
        print(f"ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print(f"pip install {' '.join(missing)}")
        return False
    
    return True


def test_vocabulary():
    """ë°©ì–¸ ì–´íœ˜ ì‚¬ì „ í™•ì¸"""
    print("\n" + "="*60)
    print("ğŸ“š ë°©ì–¸ ì–´íœ˜ ì‚¬ì „ í™•ì¸")
    print("="*60)
    
    vocab_path = 'resources/dialect_vocabulary.txt'
    
    if not os.path.exists(vocab_path):
        print(f"âŒ ì–´íœ˜ ì‚¬ì „ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {vocab_path}")
        return False
    
    with open(vocab_path, 'r', encoding='utf-8') as f:
        lines = [l.strip() for l in f if l.strip() and not l.startswith('#')]
    
    print(f"âœ… ë°©ì–¸ ì–´íœ˜ ì‚¬ì „: {len(lines)}ê°œ ë‹¨ì–´")
    
    # ì§€ì—­ë³„ í†µê³„
    region_counts = {}
    for line in lines:
        parts = line.split('|')
        if len(parts) >= 2:
            region = parts[1].strip()
            region_counts[region] = region_counts.get(region, 0) + 1
    
    print("\nì§€ì—­ë³„ ë¶„í¬:")
    for region, count in sorted(region_counts.items(), key=lambda x: x[1], reverse=True):
        print(f"  â€¢ {region}ë„: {count}ê°œ")
    
    # ìƒ˜í”Œ í‘œì‹œ
    print("\nìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):")
    for i, line in enumerate(lines[:5], 1):
        parts = line.split('|')
        if len(parts) == 3:
            word, region, meaning = [p.strip() for p in parts]
            print(f"  {i}. '{word}' ({region}ë„) â†’ {meaning}")
    
    return True


def test_model_files():
    """ëª¨ë¸ íŒŒì¼ í™•ì¸"""
    print("\n" + "="*60)
    print("ğŸ¤– ëª¨ë¸ íŒŒì¼ í™•ì¸")
    print("="*60)
    
    model_dir = 'models/dialect_binary_classifier/final_model'
    
    if not os.path.exists(model_dir):
        print(f"âŒ ëª¨ë¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_dir}")
        return False
    
    required_files = {
        'config.json': 'ëª¨ë¸ ì„¤ì •',
        'preprocessor_config.json': 'ì „ì²˜ë¦¬ ì„¤ì •'
    }
    
    model_weight_files = [
        'model.safetensors',
        'pytorch_model.bin',
        'model.pt'
    ]
    
    # í•„ìˆ˜ íŒŒì¼ í™•ì¸
    all_ok = True
    for filename, description in required_files.items():
        filepath = os.path.join(model_dir, filename)
        if os.path.exists(filepath):
            size = os.path.getsize(filepath)
            print(f"âœ… {description}: {filename} ({size:,} bytes)")
        else:
            print(f"âŒ {description}: {filename} (ì—†ìŒ)")
            all_ok = False
    
    # ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ í™•ì¸ (í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ OK)
    model_file_found = False
    for filename in model_weight_files:
        filepath = os.path.join(model_dir, filename)
        if os.path.exists(filepath):
            size = os.path.getsize(filepath)
            size_mb = size / (1024 * 1024)
            print(f"âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜: {filename} ({size_mb:.1f} MB)")
            model_file_found = True
            break
    
    if not model_file_found:
        print(f"âŒ ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        print(f"   í•„ìš”í•œ íŒŒì¼: {', '.join(model_weight_files)}")
        all_ok = False
    
    return all_ok


def test_model_loading():
    """ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("ğŸ”„ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    try:
        from src.dialect_analyzer import DialectAnalyzer
        
        print("ë°©ì–¸ ë¶„ì„ê¸°ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...")
        analyzer = DialectAnalyzer('models/dialect_binary_classifier/final_model')
        
        print(f"\nëª¨ë¸ ë¡œë“œ ìƒíƒœ: {'âœ… ì„±ê³µ' if analyzer.model_loaded else 'âŒ ì‹¤íŒ¨'}")
        print(f"ë°©ì–¸ ì–´íœ˜ ì‚¬ì „: {len(analyzer.dialect_vocab)}ê°œ ë‹¨ì–´")
        print(f"ì–µì–‘ ë¶„ì„ ê°€ëŠ¥: {'âœ…' if analyzer.model_loaded else 'âŒ'}")
        print(f"ì–´íœ˜ ë¶„ì„ ê°€ëŠ¥: {'âœ…' if len(analyzer.dialect_vocab) > 0 else 'âŒ'}")
        
        if analyzer.is_available():
            print("\nâœ… ë°©ì–¸ ê²€ì¶œ ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
            
            # ì–´íœ˜ ê²€ì¶œ í…ŒìŠ¤íŠ¸
            print("\n" + "-"*60)
            print("ğŸ“ ì–´íœ˜ ê²€ì¶œ í…ŒìŠ¤íŠ¸")
            print("-"*60)
            
            test_texts = [
                "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì°¸ ì¢‹ë„¤ìš”",  # í‘œì¤€ì–´
                "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì°¸ ì¢‹ë„¤, ê°€ê°€ë¦¬ë„ ë³´ì´ê³ ",  # ê²½ìƒë„
                "ë‹¹ê»˜ ë‚´ê°€ ê·¸ë¬ì œ? ë°¥ ë¬µì—ˆì–´?",  # ì „ë¼ë„
            ]
            
            for text in test_texts:
                detected = analyzer.detect_dialect_vocabulary(text)
                if detected:
                    print(f"\n'{text}'")
                    for word_info in detected:
                        print(f"  â†’ '{word_info['word']}' ({word_info['region']}ë„, ëœ»: {word_info['standard_meaning']})")
                else:
                    print(f"\n'{text}'")
                    print(f"  â†’ ë°©ì–¸ ë‹¨ì–´ ì—†ìŒ (í‘œì¤€ì–´)")
            
            return True
        else:
            print("\nâš ï¸  ëª¨ë¸ì€ ë¡œë“œë˜ì§€ ì•Šì•˜ì§€ë§Œ ì–´íœ˜ ë¶„ì„ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return False
            
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*60)
    print("ğŸ§ª ë°©ì–¸ ê²€ì¶œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    results = {
        'ì˜ì¡´ì„±': test_dependencies(),
        'ì–´íœ˜ ì‚¬ì „': test_vocabulary(),
        'ëª¨ë¸ íŒŒì¼': test_model_files(),
        'ëª¨ë¸ ë¡œë”©': test_model_loading()
    }
    
    print("\n" + "="*60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    
    for name, result in results.items():
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        print(f"{name}: {status}")
    
    all_passed = all(results.values())
    
    if all_passed:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ë°©ì–¸ ê²€ì¶œ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("  python main.py")
        return 0
    else:
        print("\nâš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return 1


if __name__ == "__main__":
    sys.exit(main())

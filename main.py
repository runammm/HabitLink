#!/usr/bin/env python3
"""
HabitLink Main Application
Multi-threaded Producer-Consumer architecture for real-time speech analysis
"""

import os
import sys
import time
import asyncio
import logging
import traceback
import threading
from queue import Queue, Empty
from collections import defaultdict
from datetime import datetime
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
import concurrent.futures

from src.audio_engine import AudioEngine
from src.stt import GoogleSTTDiarizer
from src.word_analyzer import WordAnalyzer
from src.speech_rate_analyzer import SpeechRateAnalyzer
from src.text_analyzer import TextAnalyzer
from src.utils import load_profanity_list

# --- Suppress library warnings ---
logging.getLogger('pyannote').setLevel(logging.WARNING)
logging.getLogger('torchaudio').setLevel(logging.ERROR)
logging.getLogger('speechbrain').setLevel(logging.ERROR)
os.environ["PYTORCH_SUPPRESS_DEPRECATION_WARNINGS"] = "1"
os.environ["PL_SUPPRESS_FORK"] = "1"


class HabitLinkSession:
    """
    Main class for managing a HabitLink analysis session with multi-threaded architecture.
    """
    
    def __init__(self):
        """Initialize the HabitLink session with default settings."""
        self.audio_engine = None
        self.diarizer = None
        self.word_analyzer = None
        self.speech_rate_analyzer = None
        self.text_analyzer = None
        self.profanity_list = []
        
        # User configuration
        self.enabled_analyses = {
            "keyword_detection": False,
            "profanity_detection": False,
            "speech_rate": False,
            "grammar": False,
            "context": False
        }
        self.custom_keywords = []
        self.target_wpm = None
        
        # Threading components
        self.task_queue = Queue()
        self.feedback_queue = Queue()
        self.stop_event = threading.Event()
        self.results_store = []
        
        # Audio recording settings
        self.chunk_duration = 10.0  # 10 seconds per chunk
        
    def initialize_components(self):
        """Initialize all analysis components."""
        print("\nğŸš€ Initializing HabitLink components...")
        
        try:
            # Initialize audio engine
            self.audio_engine = AudioEngine(samplerate=16000, channels=1)
            print("âœ… Audio engine initialized")
            
            # Initialize STT with Google Cloud
            self.diarizer = GoogleSTTDiarizer()
            print("âœ… Google Cloud STT initialized")
            
            # Initialize analyzers
            self.word_analyzer = WordAnalyzer()
            self.speech_rate_analyzer = SpeechRateAnalyzer()
            self.text_analyzer = TextAnalyzer()
            print("âœ… Analysis modules initialized")
            
            # Load profanity list
            self.profanity_list = load_profanity_list()
            print(f"âœ… Profanity list loaded ({len(self.profanity_list)} words)")
            
            return True
            
        except Exception as e:
            print(f"âŒ Error initializing components: {e}")
            traceback.print_exc()
            return False
    
    def select_analyses(self):
        """Interactive menu for users to select which analyses to enable."""
        print("\n" + "="*60)
        print("ğŸ“Š ë¶„ì„ ëª¨ë“ˆ ì„ íƒ")
        print("="*60)
        print("\nì‚¬ìš©í•  ë¶„ì„ ëª¨ë“ˆì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. íŠ¹ì • ë°˜ë³µ ë‹¨ì–´ ê²€ì¶œ")
        print("2. ë¹„ì†ì–´ ê²€ì¶œ")
        print("3. ë°œí™” ì†ë„ ë¶„ì„")
        print("4. ë¬¸ë²• ë¶„ì„")
        print("5. ë§¥ë½ ë¶„ì„")
        print("\nì—¬ëŸ¬ ê°œë¥¼ ì„ íƒí•˜ë ¤ë©´ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì„¸ìš” (ì˜ˆ: 1,3,4)")
        
        selection = input("\nì„ íƒ: ").strip()
        
        if not selection:
            print("âš ï¸ ì•„ë¬´ê²ƒë„ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë“  ë¶„ì„ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.")
            return
        
        selected_numbers = [s.strip() for s in selection.split(",")]
        
        if "1" in selected_numbers:
            self.enabled_analyses["keyword_detection"] = True
            print("\nâœ… íŠ¹ì • ë°˜ë³µ ë‹¨ì–´ ê²€ì¶œì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        if "2" in selected_numbers:
            self.enabled_analyses["profanity_detection"] = True
            print("âœ… ë¹„ì†ì–´ ê²€ì¶œì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        if "3" in selected_numbers:
            self.enabled_analyses["speech_rate"] = True
            print("âœ… ë°œí™” ì†ë„ ë¶„ì„ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        if "4" in selected_numbers:
            self.enabled_analyses["grammar"] = True
            print("âœ… ë¬¸ë²• ë¶„ì„ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        if "5" in selected_numbers:
            self.enabled_analyses["context"] = True
            print("âœ… ë§¥ë½ ë¶„ì„ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def prepare_session(self):
        """Prepare the session based on selected analyses."""
        print("\n" + "="*60)
        print("ğŸ”§ ì„¸ì…˜ ì¤€ë¹„ ì¤‘...")
        print("="*60)
        
        # If keyword detection is enabled, get keywords from user
        if self.enabled_analyses["keyword_detection"]:
            print("\n--- íŠ¹ì • ë°˜ë³µ ë‹¨ì–´ ê²€ì¶œ ì„¤ì • ---")
            keywords_input = input("ê²€ì¶œí•  ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì½¤ë§ˆë¡œ êµ¬ë¶„, ì˜ˆ: ì§€ê¸ˆ, ì´ì œ, ê·¼ë°, ì•½ê°„): ").strip()
            if keywords_input:
                self.custom_keywords = [kw.strip() for kw in keywords_input.split(",") if kw.strip()]
                print(f"âœ… ê²€ì¶œí•  ë‹¨ì–´: {', '.join(self.custom_keywords)}")
            else:
                print("âš ï¸ ë‹¨ì–´ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ ê²€ì¶œì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.")
                self.enabled_analyses["keyword_detection"] = False
        
        # If speech rate analysis is enabled, calibrate target WPM
        if self.enabled_analyses["speech_rate"]:
            print("\n--- ë°œí™” ì†ë„ ë¶„ì„ ì„¤ì • ---")
            print("ì›í•˜ëŠ” ë°œí™” ì†ë„ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´ ë‹¤ìŒ ë¬¸ì¥ì„ ì½ì–´ì£¼ì„¸ìš”:")
            calibration_text = "ì£½ëŠ” ë‚ ê¹Œì§€ í•˜ëŠ˜ì„ ìš°ëŸ¬ëŸ¬ í•œ ì  ë¶€ë„ëŸ¼ì´ ì—†ê¸°ë¥¼, ììƒˆì— ì´ëŠ” ë°”ëŒì—ë„ ë‚˜ëŠ” ê´´ë¡œì›Œí–ˆë‹¤."
            print(f"\n\"{calibration_text}\"\n")
            input("ì¤€ë¹„ê°€ ë˜ì…¨ìœ¼ë©´ Enter í‚¤ë¥¼ ëˆ„ë¥´ê³  ìœ„ ë¬¸ì¥ì„ ì½ê¸° ì‹œì‘í•˜ì„¸ìš”...")
            
            try:
                # Record calibration audio
                calibration_duration = 15.0  # 15 seconds for calibration
                calibration_path = self.audio_engine.record(calibration_duration, "calibration_temp.wav")
                
                # Process with STT
                print("ë°œí™” ì†ë„ë¥¼ ë¶„ì„ ì¤‘...")
                calibration_transcript = self.diarizer.process(calibration_path)
                
                if calibration_transcript:
                    # Analyze speech rate
                    calibration_analysis = self.speech_rate_analyzer.analyze(calibration_transcript)
                    
                    if calibration_analysis:
                        # Calculate average WPM
                        total_word_count = sum(seg.get("word_count", 0) for seg in calibration_analysis)
                        total_duration = sum(seg.get("duration", 0) for seg in calibration_analysis)
                        
                        if total_duration > 0:
                            avg_wpm = (total_word_count / total_duration) * 60
                            self.target_wpm = avg_wpm
                            self.speech_rate_analyzer.set_target_wpm(avg_wpm)
                            print(f"\nâœ… ëª©í‘œ ë°œí™” ì†ë„: {avg_wpm:.2f} WPM")
                            print(f"   (ì´ ì†ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°œí™” ì†ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.)")
                        else:
                            print("âš ï¸ ë°œí™” ì†ë„ë¥¼ ì¸¡ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    else:
                        print("âš ï¸ ë°œí™” ì†ë„ë¥¼ ì¸¡ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                else:
                    print("âš ï¸ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
                # Clean up calibration file
                if os.path.exists(calibration_path):
                    os.remove(calibration_path)
                    
            except Exception as e:
                print(f"âš ï¸ ë°œí™” ì†ë„ ì¸¡ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print("ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        print("\nâœ… ì„¸ì…˜ ì¤€ë¹„ ì™„ë£Œ!")
    
    def audio_producer(self):
        """Audio producer thread: records audio chunks and adds them to the queue."""
        print("ğŸ¤ Audio producer started. Recording...")
        chunk_counter = 0
        
        while not self.stop_event.is_set():
            try:
                chunk_counter += 1
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                audio_path = f"temp_chunk_{timestamp}_{chunk_counter}.wav"
                
                # Record audio chunk
                self.audio_engine.record(self.chunk_duration, audio_path)
                
                # Add to processing queue
                self.task_queue.put({
                    "audio_path": audio_path,
                    "chunk_id": chunk_counter,
                    "timestamp": time.time()
                })
                
            except Exception as e:
                if not self.stop_event.is_set():
                    print(f"âŒ Error in audio producer: {e}")
        
        print("ğŸ¤ Audio producer stopping.")
    
    def analysis_consumer(self):
        """Analysis consumer thread: processes audio from the queue."""
        print("ğŸ“Š Analysis consumer started.")
        
        # Create event loop for this thread
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        while not self.stop_event.is_set() or not self.task_queue.empty():
            try:
                # Get task from queue with timeout
                task = self.task_queue.get(timeout=1)
                audio_path = task["audio_path"]
                chunk_id = task["chunk_id"]
                
                # Process the audio chunk
                results = loop.run_until_complete(self._process_audio_chunk(audio_path, chunk_id))
                
                # Store results
                if results:
                    self.results_store.append(results)
                
                # Clean up audio file
                if os.path.exists(audio_path):
                    os.remove(audio_path)
                
                self.task_queue.task_done()
                
            except Empty:
                continue
            except Exception as e:
                if not self.stop_event.is_set():
                    print(f"âŒ Error in analysis consumer: {e}")
                    traceback.print_exc()
        
        loop.close()
        print("ğŸ“Š Analysis consumer stopping.")
    
    async def _process_audio_chunk(self, audio_path: str, chunk_id: int) -> Optional[Dict[str, Any]]:
        """Process a single audio chunk through the analysis pipeline."""
        try:
            # Step 1: Diarization
            diarized_transcript = self.diarizer.process(audio_path)
            
            if not diarized_transcript:
                return None
            
            # Step 2: Run enabled analyses
            results = {
                "chunk_id": chunk_id,
                "timestamp": time.time(),
                "transcript": diarized_transcript,
                "detected_keywords": [],
                "detected_profanity": [],
                "speech_rate_analysis": [],
                "grammar_analysis": [],
                "context_analysis": []
            }
            
            # Prepare concurrent tasks
            loop = asyncio.get_running_loop()
            tasks = []
            
            with concurrent.futures.ThreadPoolExecutor() as pool:
                # Keyword detection (fast, local)
                if self.enabled_analyses["keyword_detection"] and self.custom_keywords:
                    keyword_task = loop.run_in_executor(
                        pool, self.word_analyzer.analyze, diarized_transcript, self.custom_keywords
                    )
                    tasks.append(("keywords", keyword_task))
                
                # Profanity detection (fast, local)
                if self.enabled_analyses["profanity_detection"]:
                    profanity_task = loop.run_in_executor(
                        pool, self.word_analyzer.analyze, diarized_transcript, self.profanity_list
                    )
                    tasks.append(("profanity", profanity_task))
                
                # Speech rate analysis (fast, local)
                if self.enabled_analyses["speech_rate"]:
                    speech_rate_task = loop.run_in_executor(
                        pool, self.speech_rate_analyzer.analyze, diarized_transcript
                    )
                    tasks.append(("speech_rate", speech_rate_task))
                
                # LLM-based analysis (slow, network-bound) - runs asynchronously
                if self.enabled_analyses["grammar"] or self.enabled_analyses["context"]:
                    llm_task = self.text_analyzer.analyze(diarized_transcript)
                    tasks.append(("llm", llm_task))
                
                # Wait for all tasks to complete
                for task_name, task in tasks:
                    try:
                        result = await task
                        
                        if task_name == "keywords":
                            results["detected_keywords"] = result
                            # Real-time feedback for keywords
                            self._send_keyword_feedback(result, chunk_id)
                        
                        elif task_name == "profanity":
                            results["detected_profanity"] = result
                            # Real-time feedback for profanity
                            self._send_profanity_feedback(result, chunk_id)
                        
                        elif task_name == "speech_rate":
                            results["speech_rate_analysis"] = result
                            # Real-time feedback for speech rate
                            self._send_speech_rate_feedback(result, chunk_id)
                        
                        elif task_name == "llm":
                            results["grammar_analysis"] = result.get("grammar_errors", [])
                            results["context_analysis"] = result.get("context_errors", [])
                            # LLM results are primarily for the final report
                    
                    except Exception as e:
                        print(f"âš ï¸ Error in {task_name} analysis: {e}")
            
            return results
            
        except Exception as e:
            print(f"âŒ Error processing audio chunk {chunk_id}: {e}")
            return None
    
    def _send_keyword_feedback(self, detected_keywords: List[Dict], chunk_id: int):
        """Send real-time feedback for detected keywords."""
        if detected_keywords:
            for item in detected_keywords:
                keyword = item.get("keyword")
                timestamp = item.get("timestamp", 0)
                speaker = item.get("speaker", "UNKNOWN")
                self.feedback_queue.put(
                    f"[ì²­í¬ {chunk_id}] ğŸ” í‚¤ì›Œë“œ ê²€ì¶œ: '{keyword}' ({speaker}, {timestamp:.2f}s)"
                )
    
    def _send_profanity_feedback(self, detected_profanity: List[Dict], chunk_id: int):
        """Send real-time feedback for detected profanity."""
        if detected_profanity:
            for item in detected_profanity:
                profanity = item.get("keyword")
                timestamp = item.get("timestamp", 0)
                speaker = item.get("speaker", "UNKNOWN")
                self.feedback_queue.put(
                    f"[ì²­í¬ {chunk_id}] âš ï¸ ë¹„ì†ì–´ ê²€ì¶œ: '{profanity}' ({speaker}, {timestamp:.2f}s)"
                )
    
    def _send_speech_rate_feedback(self, speech_rate_analysis: List[Dict], chunk_id: int):
        """Send real-time feedback for speech rate analysis."""
        if speech_rate_analysis and self.target_wpm:
            for segment in speech_rate_analysis:
                comparison = segment.get("comparison")
                if comparison == "too_fast":
                    wpm = segment.get("wpm", 0)
                    speaker = segment.get("speaker", "UNKNOWN")
                    self.feedback_queue.put(
                        f"[ì²­í¬ {chunk_id}] ğŸƒ ë°œí™” ì†ë„ê°€ ë¹ ë¦…ë‹ˆë‹¤: {wpm:.0f} WPM ({speaker})"
                    )
                elif comparison == "too_slow":
                    wpm = segment.get("wpm", 0)
                    speaker = segment.get("speaker", "UNKNOWN")
                    self.feedback_queue.put(
                        f"[ì²­í¬ {chunk_id}] ğŸ¢ ë°œí™” ì†ë„ê°€ ëŠë¦½ë‹ˆë‹¤: {wpm:.0f} WPM ({speaker})"
                    )
    
    def feedback_loop(self):
        """Main thread feedback loop: prints real-time feedback to the console."""
        print("\n" + "="*60)
        print("ğŸ™ï¸ ì„¸ì…˜ ì‹œì‘")
        print("="*60)
        print("ì‹¤ì‹œê°„ í”¼ë“œë°±ì´ ì•„ë˜ì— í‘œì‹œë©ë‹ˆë‹¤.")
        print("ì„¸ì…˜ì„ ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")
        print("="*60 + "\n")
        
        while not self.stop_event.is_set():
            try:
                # Get feedback from queue with timeout
                feedback = self.feedback_queue.get(timeout=0.1)
                print(feedback)
            except Empty:
                continue
    
    def generate_summary_report(self):
        """Generate and print a comprehensive summary report after the session ends."""
        print("\n\n" + "="*60)
        print("ğŸ“‹ ì„¸ì…˜ ìš”ì•½ ë¦¬í¬íŠ¸")
        print("="*60)
        
        if not self.results_store:
            print("\në¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # Aggregate all transcripts
        print("\n--- âœ… ì „ì²´ ëŒ€í™” ë‚´ìš© ---")
        for result in self.results_store:
            chunk_id = result.get("chunk_id")
            transcript = result.get("transcript", [])
            if transcript:
                print(f"\n[ì²­í¬ {chunk_id}]")
                for segment in transcript:
                    speaker = segment.get("speaker", "UNKNOWN")
                    start = segment.get("start", 0)
                    end = segment.get("end", 0)
                    text = segment.get("text", "")
                    print(f"  [{start:.2f}s - {end:.2f}s] {speaker}: {text}")
        
        # Keyword detection summary
        if self.enabled_analyses["keyword_detection"]:
            print("\n--- ğŸ” í‚¤ì›Œë“œ ê²€ì¶œ ìš”ì•½ ---")
            all_keywords = []
            for result in self.results_store:
                all_keywords.extend(result.get("detected_keywords", []))
            
            if all_keywords:
                keyword_counts = defaultdict(int)
                for item in all_keywords:
                    keyword_counts[item["keyword"].lower()] += 1
                
                print(f"ì´ {len(all_keywords)}íšŒ ê²€ì¶œ:")
                for keyword, count in sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True):
                    print(f"  - '{keyword}': {count}íšŒ")
            else:
                print("ê²€ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # Profanity detection summary
        if self.enabled_analyses["profanity_detection"]:
            print("\n--- âš ï¸ ë¹„ì†ì–´ ê²€ì¶œ ìš”ì•½ ---")
            all_profanity = []
            for result in self.results_store:
                all_profanity.extend(result.get("detected_profanity", []))
            
            if all_profanity:
                profanity_counts = defaultdict(int)
                for item in all_profanity:
                    profanity_counts[item["keyword"].lower()] += 1
                
                print(f"ì´ {len(all_profanity)}íšŒ ê²€ì¶œ:")
                for profanity, count in sorted(profanity_counts.items(), key=lambda x: x[1], reverse=True):
                    print(f"  - '{profanity}': {count}íšŒ")
            else:
                print("ê²€ì¶œëœ ë¹„ì†ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # Speech rate analysis summary
        if self.enabled_analyses["speech_rate"]:
            print("\n--- ğŸƒ ë°œí™” ì†ë„ ë¶„ì„ ìš”ì•½ ---")
            all_speech_rate = []
            for result in self.results_store:
                all_speech_rate.extend(result.get("speech_rate_analysis", []))
            
            if all_speech_rate:
                total_word_count = sum(seg.get("word_count", 0) for seg in all_speech_rate)
                total_duration = sum(seg.get("duration", 0) for seg in all_speech_rate)
                
                if total_duration > 0:
                    overall_wpm = (total_word_count / total_duration) * 60
                    print(f"ì „ì²´ í‰ê·  ë°œí™” ì†ë„: {overall_wpm:.2f} WPM")
                    
                    if self.target_wpm:
                        print(f"ëª©í‘œ ë°œí™” ì†ë„: {self.target_wpm:.2f} WPM")
                        
                        # Count too_fast and too_slow instances
                        too_fast = sum(1 for seg in all_speech_rate if seg.get("comparison") == "too_fast")
                        too_slow = sum(1 for seg in all_speech_rate if seg.get("comparison") == "too_slow")
                        good = sum(1 for seg in all_speech_rate if seg.get("comparison") == "good")
                        
                        print(f"\në°œí™” ì†ë„ ë¶„í¬:")
                        print(f"  - ì ì ˆ: {good}íšŒ")
                        print(f"  - ë„ˆë¬´ ë¹ ë¦„: {too_fast}íšŒ")
                        print(f"  - ë„ˆë¬´ ëŠë¦¼: {too_slow}íšŒ")
                    
                    # Speaker breakdown
                    speaker_stats = defaultdict(lambda: {"word_count": 0, "duration": 0})
                    for seg in all_speech_rate:
                        speaker = seg.get("speaker", "UNKNOWN")
                        speaker_stats[speaker]["word_count"] += seg.get("word_count", 0)
                        speaker_stats[speaker]["duration"] += seg.get("duration", 0)
                    
                    print("\ní™”ìë³„ ë°œí™” ì†ë„:")
                    for speaker, stats in speaker_stats.items():
                        if stats["duration"] > 0:
                            speaker_wpm = (stats["word_count"] / stats["duration"]) * 60
                            print(f"  - {speaker}: {speaker_wpm:.2f} WPM")
            else:
                print("ë°œí™” ì†ë„ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # Grammar analysis summary
        if self.enabled_analyses["grammar"]:
            print("\n--- ğŸ§ ë¬¸ë²• ë¶„ì„ ìš”ì•½ ---")
            all_grammar_errors = []
            for result in self.results_store:
                all_grammar_errors.extend(result.get("grammar_analysis", []))
            
            if all_grammar_errors:
                print(f"ì´ {len(all_grammar_errors)}ê°œì˜ ë¬¸ë²• ì˜¤ë¥˜ ë°œê²¬:")
                for i, error in enumerate(all_grammar_errors[:10], 1):  # Show first 10
                    details = error.get("error_details", {})
                    print(f"\n  {i}. [{error.get('speaker')}] '{details.get('original')}' â†’ '{details.get('corrected')}'")
                    print(f"     ì„¤ëª…: {details.get('explanation')}")
                
                if len(all_grammar_errors) > 10:
                    print(f"\n  ... ê·¸ ì™¸ {len(all_grammar_errors) - 10}ê°œ ë”")
            else:
                print("ë¬¸ë²• ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Context analysis summary
        if self.enabled_analyses["context"]:
            print("\n--- ğŸ§  ë§¥ë½ ë¶„ì„ ìš”ì•½ ---")
            all_context_errors = []
            for result in self.results_store:
                all_context_errors.extend(result.get("context_analysis", []))
            
            if all_context_errors:
                print(f"ì´ {len(all_context_errors)}ê°œì˜ ë§¥ë½ ì˜¤ë¥˜ ë°œê²¬:")
                for i, error in enumerate(all_context_errors[:5], 1):  # Show first 5
                    print(f"\n  {i}. [{error.get('speaker')}] \"{error.get('utterance')}\"")
                    print(f"     ë¶„ì„: {error.get('reasoning')}")
                
                if len(all_context_errors) > 5:
                    print(f"\n  ... ê·¸ ì™¸ {len(all_context_errors) - 5}ê°œ ë”")
            else:
                print("ë§¥ë½ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        print("\n" + "="*60)
        print("ì„¸ì…˜ ì¢…ë£Œ")
        print("="*60)
    
    def run(self):
        """Run the main HabitLink session."""
        # Initialize components
        if not self.initialize_components():
            print("âŒ ì´ˆê¸°í™” ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        # Select analyses
        self.select_analyses()
        
        # Check if at least one analysis is enabled
        if not any(self.enabled_analyses.values()):
            print("\nâš ï¸ í™œì„±í™”ëœ ë¶„ì„ì´ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        # Prepare session
        self.prepare_session()
        
        # Start threads
        producer_thread = threading.Thread(target=self.audio_producer, daemon=True)
        consumer_thread = threading.Thread(target=self.analysis_consumer, daemon=True)
        
        producer_thread.start()
        consumer_thread.start()
        
        try:
            # Main feedback loop
            self.feedback_loop()
        except KeyboardInterrupt:
            print("\n\nâ¸ï¸ ì„¸ì…˜ì„ ì¢…ë£Œí•˜ëŠ” ì¤‘...")
            self.stop_event.set()
        
        # Wait for threads to finish
        print("ë§ˆì§€ë§‰ ë¶„ì„ì„ ì™„ë£Œí•˜ëŠ” ì¤‘...")
        producer_thread.join(timeout=2)
        consumer_thread.join(timeout=10)
        
        # Generate summary report
        self.generate_summary_report()


def main():
    """Main entry point for the HabitLink application."""
    load_dotenv()
    
    # Pre-flight checks
    if not os.getenv("GROQ_API_KEY"):
        print("âŒ Error: GROQ_API_KEY not found in .env file.")
        print("Please set your GROQ_API_KEY to use LLM-based analysis features.")
        return
    
    # Check Google Cloud credentials
    if not os.getenv("GOOGLE_APPLICATION_CREDENTIALS") and not os.path.exists("gcp_credentials.json"):
        print("âŒ Error: Google Cloud credentials not found.")
        print("Please either:")
        print("  1. Set GOOGLE_APPLICATION_CREDENTIALS in your .env file, or")
        print("  2. Run 'gcloud auth application-default login'")
        return
    
    print("="*60)
    print("ğŸ¯ HabitLink: AI-Powered Korean Speech Habit Correction System")
    print("="*60)
    print("\nì‹¤ì‹œê°„ ìŒì„± ë¶„ì„ ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    # Create and run session
    session = HabitLinkSession()
    session.run()
    
    print("\n\nê°ì‚¬í•©ë‹ˆë‹¤. HabitLinkë¥¼ ì‚¬ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ‘‹")


if __name__ == "__main__":
    main()

